# jv/BUILD
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Copyright 2016, 2017 Google, Inc.
# Author: mjansche@google.com (Martin Jansche)

package(default_visibility = ["//visibility:public"])

sh_test(
    name = "ipa_phonemes_are_uniquely_decodable",
    timeout = "short",
    srcs = ["//utils:eval.sh"],
    args = [
        """
        cut -f 2 $(location phonemes.txt) |
        $(location //utils:uniquely_decodable)
        """,
    ],
    data = [
        "phonemes.txt",
        "//utils:uniquely_decodable",
    ],
)

genrule(
    name = "make_custom_phoneme_syms",
    srcs = ["phonemes.txt"],
    outs = ["custom_phoneme.syms"],
    cmd = """
          awk 'BEGIN {printf "<epsilon>\\t0\\n"}
               {printf "%s\\t%d\\n", $$1, NR}' \
            $< >$@
          """,
)

# It is difficult to get rid of phoneme.syms: doing so would make compiling the
# G2P grammar much messier, since the location of phoneme.syms must be known.
# Compromise: keep phoneme.syms and ensure that it matches phonemes.txt.
sh_test(
    name = "phoneme_syms_is_current",
    timeout = "short",
    srcs = ["//utils:eval.sh"],
    args = ["diff -u $(location phoneme.syms) $(location custom_phoneme.syms)"],
    data = [
        "custom_phoneme.syms",
        "phoneme.syms",
    ],
)

genrule(
    name = "compile_javanese_grm",
    srcs = [
        "javanese.grm",
        "grapheme.syms",
        "phoneme.syms",
    ],
    outs = ["javanese.far"],
    cmd = """
          $(location @thrax//:thraxcompiler) \
            --input_grammar=$(location javanese.grm) \
            --output_far=$@
          """,
    tools = ["@thrax//:thraxcompiler"],
)

py_binary(
    name = "tokenize",
    srcs = ["tokenize.py"],
    srcs_version = "PY2AND3",
    deps = ["//utils:utf8"],
)

genrule(
    name = "make_jv_lexicon",
    srcs = [
        "//third_party/wikimedia:jv_wiki_cleaned.txt",
        "data/prompts.txt",
        "javanese.far",
        "phoneme.syms",
    ],
    outs = [
        "jv_bad_tokens.txt",
        "jv_unpronouncable.txt",
        "jv_lexicon.txt",
    ],
    cmd = """
          cat $(location //third_party/wikimedia:jv_wiki_cleaned.txt) \
              $(location data/prompts.txt) |
          $(location :tokenize) \
            2> $(location jv_bad_tokens.txt) |
          $(location //utils:freq) |
          cut -f 1 |
          $(location //utils:thrax_g2p) \
            --far=$(location javanese.far) \
            --phoneme_syms=$(location phoneme.syms) \
            1> $(location jv_lexicon.txt) \
            2> $(location jv_unpronouncable.txt)
          """,
    tools = [
        ":tokenize",
        "//utils:freq",
        "//utils:thrax_g2p",
    ],
)

genrule(
    name = "make_en_lexicon",
    srcs = [
        "//third_party/wikimedia:simple_wiktionary.txt",
        "data/lexicon.tsv",
        "javanese.far",
        "phoneme.syms",
    ],
    outs = [
        "en_bad_tokens.txt",
        "en_unpronouncable.txt",
        "en_lexicon.txt",
    ],
    cmd = """
          $(location :tokenize) \
            < $(location //third_party/wikimedia:simple_wiktionary.txt) \
            2> $(location en_bad_tokens.txt) |
          $(location //utils:freq) |
          cut -f 1 |
          $(location //utils:thrax_g2p) \
            --far=$(location javanese.far) \
            --phoneme_syms=$(location phoneme.syms) \
            2> $(location en_unpronouncable.txt) |
          $(location //utils:merge_lexicons) \
            - \
            $(location data/lexicon.tsv) \
            > $(location en_lexicon.txt)
          """,
    tools = [
        ":tokenize",
        "//utils:freq",
        "//utils:merge_lexicons",
        "//utils:thrax_g2p",
    ],
)
